{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bb97dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import pycytominer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a67ba392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load custom collection of functions\n",
    "import sys\n",
    "sys.path.append('/home/schmiedc/FMP_Docs/Projects/Bioactives_data/notebooks/')\n",
    "import utility_functions as UTIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "922ead3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_directory = \"/home/schmiedc/FMP_Docs/Projects/Bioactives_data/\"\n",
    "\n",
    "input_path = parent_directory + \"results/\"\n",
    "output_path = input_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb89b242",
   "metadata": {},
   "source": [
    "# HepG2 cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2af24891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10735, 2984)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_HepG2 = pd.read_csv(input_path + \"2023-04-11_Bioactives_HepG2_raw.csv\")\n",
    "file_HepG2_type = '/*[0-9]_' + 'MEDINA_HepG2_raw.csv'\n",
    "files_HepG2 = glob.glob(input_path + file_HepG2_type)\n",
    "\n",
    "### gets latest file\n",
    "max_file_HepG2 = max(files_HepG2, key=os.path.getctime)\n",
    "\n",
    "### load file\n",
    "data_HepG2 = pd.read_csv(max_file_HepG2)\n",
    "data_HepG2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e776e35",
   "metadata": {},
   "source": [
    "# HepG2 Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b63fbff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of features: 2977\n"
     ]
    }
   ],
   "source": [
    "######\n",
    "### helper functions extracts metadata columns and define feature columns\n",
    "Features_HepG2 = UTIL.get_feature_vector(data_HepG2)\n",
    "Meta_Features_HepG2 = set(data_HepG2.columns) - set(Features_HepG2)\n",
    "\n",
    "### convert sets to list\n",
    "Features_HepG2 = list(Features_HepG2)\n",
    "Meta_Features_HepG2 = list(Meta_Features_HepG2)\n",
    "\n",
    "print(\"Total number of features:\", len(Features_HepG2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cef2720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch R1 Plate B1001 normalized\n",
      "Batch R1 Plate B1002 normalized\n",
      "Batch R1 Plate B1003 normalized\n",
      "Batch R1 Plate B1004 normalized\n",
      "Batch R1 Plate B1005 normalized\n",
      "Batch R1 Plate B1006 normalized\n",
      "Batch R1 Plate B1007 normalized\n",
      "Batch R2 Plate B1001 normalized\n",
      "Batch R2 Plate B1002 normalized\n",
      "Batch R2 Plate B1003 normalized\n",
      "Batch R2 Plate B1004 normalized\n",
      "Batch R2 Plate B1005 normalized\n",
      "Batch R2 Plate B1006 normalized\n",
      "Batch R2 Plate B1007 normalized\n",
      "Batch R3 Plate B1001 normalized\n",
      "Batch R3 Plate B1002 normalized\n",
      "Batch R3 Plate B1003 normalized\n",
      "Batch R3 Plate B1004 normalized\n",
      "Batch R3 Plate B1005 normalized\n",
      "Batch R3 Plate B1006 normalized\n",
      "Batch R3 Plate B1007 normalized\n",
      "Batch R4 Plate B1001 normalized\n",
      "Batch R4 Plate B1002 normalized\n",
      "Batch R4 Plate B1003 normalized\n",
      "Batch R4 Plate B1004 normalized\n",
      "Batch R4 Plate B1005 normalized\n",
      "Batch R4 Plate B1006 normalized\n",
      "Batch R4 Plate B1007 normalized\n",
      "28 Plates Normalized\n",
      "Normalized Data has shape: (10735, 2984)\n"
     ]
    }
   ],
   "source": [
    "### Method to normalize the data:\n",
    "#### options - [\"standardize\", \"robustize\", \"mad_robustize\", \"spherize\"]\n",
    "#### defaults to \"robustize\"\n",
    "normalizer = \"mad_robustize\" \n",
    "\n",
    "### we have to normalize each plate seperate\n",
    "plates = [\"B1001\",\"B1002\",\"B1003\",\"B1004\",\"B1005\",\"B1006\",\"B1007\", \"Ref_Plate\", \"FMP_Plate\"]\n",
    "batches = [\"R1\", \"R2\", \"R3\", \"R4\"]\n",
    "Data_Temp = []\n",
    "Data_Norm_Temp = []\n",
    "\n",
    "for batch in batches:\n",
    "    for plate in plates:\n",
    "        if len(data_HepG2.loc[(data_HepG2[\"Metadata_Batch\"] == batch) & (data_HepG2[\"Metadata_Plate\"] == plate)]) == 0:\n",
    "            continue\n",
    "        Data_Temp = pycytominer.normalize(\n",
    "                    profiles = data_HepG2.loc[(data_HepG2[\"Metadata_Batch\"] == batch) & (data_HepG2[\"Metadata_Plate\"] == plate)],\n",
    "                    features = Features_HepG2,\n",
    "                    meta_features = Meta_Features_HepG2,\n",
    "                    method = normalizer, ### Method to normalize the data\n",
    "                    samples = \"Metadata_EOS == 'DMSO'\" # normalization performed on neg. controls\n",
    "                    )\n",
    "        Data_Norm_Temp.append(Data_Temp)\n",
    "        print(\"Batch\", batch, \"Plate\", plate, \"normalized\")\n",
    "        \n",
    "print(len(Data_Norm_Temp), \"Plates Normalized\")\n",
    "\n",
    "### concat list\n",
    "Data_Norm_HepG2 = pd.concat(Data_Norm_Temp)\n",
    "Data_Norm_HepG2 = Data_Norm_HepG2.reset_index(drop = True)\n",
    "print(\"Normalized Data has shape:\", Data_Norm_HepG2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fb6001",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b5563f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_Norm_HepG2 = output_path + str(date.today()) + \"_MEDINA_HepG2_norm.csv\"\n",
    "Data_Norm_HepG2.to_csv(filename_Norm_HepG2, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e8d563",
   "metadata": {},
   "source": [
    "# HepG2 consensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92831285",
   "metadata": {},
   "outputs": [],
   "source": [
    "## gets feature vector\n",
    "Features_Data_Norm_HepG2 = UTIL.get_feature_vector(Data_Norm_HepG2)\n",
    "\n",
    "## adds the object count as feature column\n",
    "Features_Data_Norm_HepG2.append(\"Metadata_Object_Count\") \n",
    "Features_Data_Norm_HepG2 = list(Features_Data_Norm_HepG2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4c0e0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_HepG2_Norm_Median = pycytominer.consensus(\n",
    "        profiles = Data_Norm_HepG2, # A file or pandas DataFrame of profile data\n",
    "        replicate_columns = [\"Metadata_EOS\", \"Metadata_Plate\", \"Metadata_Concentration\", \"Metadata_Partner\"], # Metadata columns indicating which replicates to collapse, defaults to [“Metadata_Plate”, “Metadata_Well”]\n",
    "        operation = \"median\", # (str) – The method used to form consensus profiles, defaults to “median”\n",
    "        features = Features_Data_Norm_HepG2, # (str, list) – The features to collapse, defaults to “infer”\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5ee125a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_HepG2_Norm_Median = output_path + str(date.today()) + \"_MEDINA_HepG2_norm_median_full.csv\"\n",
    "Data_HepG2_Norm_Median.to_csv(filename_HepG2_Norm_Median , index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
